{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from model_paired_ae_emma import MultimodalAE, Encoder, Decoder\n",
    "from src.dataset import generate_datasets\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading paired dataset\n",
      "Loading paired dataset\n"
     ]
    }
   ],
   "source": [
    "# Génération des ensembles de données\n",
    "train_datasets = generate_datasets(suffix='5_diff', type='paired', train=True, test=False)\n",
    "test_datasets = generate_datasets(suffix='5_diff', type='paired', train=False, test=True)\n",
    "\n",
    "\n",
    "# Création des chargeurs de données\n",
    "train_loaders = [DataLoader(dataset, batch_size=32, shuffle=True) for dataset in train_datasets]\n",
    "test_loaders = [DataLoader(dataset, batch_size=32, shuffle=False) for dataset in test_datasets]\n",
    "\n",
    "\n",
    "# Obtenez les dimensions d'entrée à partir des ensembles de données\n",
    "n_inputs1 = train_datasets[0][0][0].shape[0]  # La taille du vecteur de caractéristiques pour la modalité 1\n",
    "n_inputs2 = train_datasets[1][0][0].shape[0]  # La taille du vecteur de caractéristiques pour la modalité 2\n",
    "n_inputs3 = train_datasets[2][0][0].shape[0]  # La taille du vecteur de caractéristiques pour la modalité 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialisation des modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dims = 20   \n",
    "n_hiddens = 256 \n",
    "\n",
    "# Création du modèle\n",
    "encoder1 = Encoder(n_inputs1, latent_dims, n_hiddens)\n",
    "encoder2 = Encoder(n_inputs2, latent_dims, n_hiddens)\n",
    "encoder3 = Encoder(n_inputs3, latent_dims, n_hiddens)\n",
    "\n",
    "z1 = encoder1(train_datasets[0][0][0])\n",
    "z2 = encoder2(train_datasets[1][0][0])\n",
    "z3 = encoder3(train_datasets[2][0][0])\n",
    "\n",
    "decoder1 = Decoder(n_inputs1, latent_dims, n_hiddens)\n",
    "decoder2 = Decoder(n_inputs2, latent_dims, n_hiddens)\n",
    "decoder3 = Decoder(n_inputs3, latent_dims, n_hiddens)\n",
    "\n",
    "model1 = MultimodalAE(encoder=encoder1, decoder=decoder1)\n",
    "model2 = MultimodalAE(encoder=encoder2, decoder=decoder2)\n",
    "model1_2 = MultimodalAE(encoder=encoder1, decoder=decoder2)\n",
    "model2_1 = MultimodalAE(encoder=encoder2, decoder=decoder1)\n",
    "model3 = MultimodalAE(encoder=encoder3, decoder=decoder3)\n",
    "model1_3 = MultimodalAE(encoder=encoder1, decoder=decoder3)\n",
    "model3_1 = MultimodalAE(encoder=encoder3, decoder=decoder1)\n",
    "model2_3 = MultimodalAE(encoder=encoder2, decoder=decoder3)\n",
    "model3_2 = MultimodalAE(encoder=encoder3, decoder=decoder2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Critère et optimiseur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "critere = nn.MSELoss()\n",
    "lr = 0.001\n",
    "optimizer1 = torch.optim.Adam(model1.parameters(), lr=lr)\n",
    "optimizer2 = torch.optim.Adam(model2.parameters(), lr=lr)\n",
    "optimizer1_2 = torch.optim.Adam(model1_2.parameters(), lr=lr)\n",
    "optimizer2_1 = torch.optim.Adam(model2_1.parameters(), lr=lr)\n",
    "optimizer3 = torch.optim.Adam(model3.parameters(), lr=lr)\n",
    "optimizer1_3 = torch.optim.Adam(model1_3.parameters(), lr=lr)\n",
    "optimizer3_1 = torch.optim.Adam(model3_1.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 0 -> loss totale : 0.4336608052253723  loss1 : 0.4336608052253723  loss3 : 0.9729708433151245  loss1_3 : 0.9894567728042603  loss3_1 : 0.9875562787055969\n",
      " Epoch 1 -> loss totale : 0.4058211147785187  loss1 : 0.4058211147785187  loss3 : 1.020359754562378  loss1_3 : 1.0347464084625244  loss3_1 : 1.0722404718399048\n",
      " Epoch 2 -> loss totale : 0.33963486552238464  loss1 : 0.33963486552238464  loss3 : 1.008538007736206  loss1_3 : 1.0214464664459229  loss3_1 : 0.9738199710845947\n",
      " Epoch 3 -> loss totale : 0.3018522262573242  loss1 : 0.3018522262573242  loss3 : 0.9820758700370789  loss1_3 : 1.0002148151397705  loss3_1 : 1.0245037078857422\n",
      " Epoch 4 -> loss totale : 0.2871735990047455  loss1 : 0.2871735990047455  loss3 : 0.9702557325363159  loss1_3 : 0.9871752858161926  loss3_1 : 0.9720081686973572\n",
      " Epoch 5 -> loss totale : 0.25777873396873474  loss1 : 0.25777873396873474  loss3 : 1.015305519104004  loss1_3 : 1.0260915756225586  loss3_1 : 1.0100315809249878\n",
      " Epoch 6 -> loss totale : 0.25657588243484497  loss1 : 0.25657588243484497  loss3 : 0.9991709589958191  loss1_3 : 1.0123484134674072  loss3_1 : 1.0395750999450684\n",
      " Epoch 7 -> loss totale : 0.24184465408325195  loss1 : 0.24184465408325195  loss3 : 1.0444629192352295  loss1_3 : 1.059871792793274  loss3_1 : 0.998358428478241\n",
      " Epoch 8 -> loss totale : 0.22610227763652802  loss1 : 0.22610227763652802  loss3 : 0.9649034738540649  loss1_3 : 0.9808045625686646  loss3_1 : 0.9668645262718201\n",
      " Epoch 9 -> loss totale : 0.22018735110759735  loss1 : 0.22018735110759735  loss3 : 1.019047498703003  loss1_3 : 1.0407222509384155  loss3_1 : 1.0844767093658447\n",
      " Epoch 10 -> loss totale : 0.19831645488739014  loss1 : 0.19831645488739014  loss3 : 1.0987173318862915  loss1_3 : 1.1141494512557983  loss3_1 : 1.0412262678146362\n",
      " Epoch 11 -> loss totale : 0.18285049498081207  loss1 : 0.18285049498081207  loss3 : 0.9872026443481445  loss1_3 : 1.006326675415039  loss3_1 : 1.0948867797851562\n",
      " Epoch 12 -> loss totale : 0.18009743094444275  loss1 : 0.18009743094444275  loss3 : 1.0146113634109497  loss1_3 : 1.0411396026611328  loss3_1 : 0.9903918504714966\n",
      " Epoch 13 -> loss totale : 0.17168115079402924  loss1 : 0.17168115079402924  loss3 : 0.938616931438446  loss1_3 : 0.9649192690849304  loss3_1 : 1.0481373071670532\n",
      " Epoch 14 -> loss totale : 0.16935132443904877  loss1 : 0.16935132443904877  loss3 : 1.0078685283660889  loss1_3 : 1.035337209701538  loss3_1 : 1.046934962272644\n",
      " Epoch 15 -> loss totale : 0.16915300488471985  loss1 : 0.16915300488471985  loss3 : 0.9484516382217407  loss1_3 : 0.9627453684806824  loss3_1 : 0.9463100433349609\n",
      " Epoch 16 -> loss totale : 0.16148224472999573  loss1 : 0.16148224472999573  loss3 : 1.006783127784729  loss1_3 : 1.0318551063537598  loss3_1 : 0.9914342164993286\n",
      " Epoch 17 -> loss totale : 0.162459596991539  loss1 : 0.162459596991539  loss3 : 0.9616072773933411  loss1_3 : 0.9846543073654175  loss3_1 : 1.025683045387268\n",
      " Epoch 18 -> loss totale : 0.15651609003543854  loss1 : 0.15651609003543854  loss3 : 1.0862007141113281  loss1_3 : 1.1040081977844238  loss3_1 : 1.0293469429016113\n",
      " Epoch 19 -> loss totale : 0.14204780757427216  loss1 : 0.14204780757427216  loss3 : 1.0492351055145264  loss1_3 : 1.0724027156829834  loss3_1 : 1.0767794847488403\n",
      " Epoch 20 -> loss totale : 0.14742331206798553  loss1 : 0.14742331206798553  loss3 : 0.9700210690498352  loss1_3 : 0.9876646995544434  loss3_1 : 0.9593212008476257\n",
      " Epoch 21 -> loss totale : 0.1423887312412262  loss1 : 0.1423887312412262  loss3 : 1.0540331602096558  loss1_3 : 1.0827274322509766  loss3_1 : 1.0935134887695312\n",
      " Epoch 22 -> loss totale : 0.13825362920761108  loss1 : 0.13825362920761108  loss3 : 1.016150712966919  loss1_3 : 1.0424683094024658  loss3_1 : 1.063044548034668\n",
      " Epoch 23 -> loss totale : 0.14156872034072876  loss1 : 0.14156872034072876  loss3 : 1.0280911922454834  loss1_3 : 1.048822045326233  loss3_1 : 1.0059188604354858\n",
      " Epoch 24 -> loss totale : 0.13593900203704834  loss1 : 0.13593900203704834  loss3 : 1.044665813446045  loss1_3 : 1.0693830251693726  loss3_1 : 1.0261974334716797\n",
      " Epoch 25 -> loss totale : 0.13964541256427765  loss1 : 0.13964541256427765  loss3 : 0.9542039036750793  loss1_3 : 0.9867644309997559  loss3_1 : 1.0439980030059814\n",
      " Epoch 26 -> loss totale : 0.12860986590385437  loss1 : 0.12860986590385437  loss3 : 0.9095810055732727  loss1_3 : 0.941405177116394  loss3_1 : 1.021230936050415\n",
      " Epoch 27 -> loss totale : 0.12807296216487885  loss1 : 0.12807296216487885  loss3 : 0.9669089317321777  loss1_3 : 0.9982295036315918  loss3_1 : 0.9910268783569336\n",
      " Epoch 28 -> loss totale : 0.12298350781202316  loss1 : 0.12298350781202316  loss3 : 0.972359299659729  loss1_3 : 1.0045055150985718  loss3_1 : 1.0493639707565308\n",
      " Epoch 29 -> loss totale : 0.12532754242420197  loss1 : 0.12532754242420197  loss3 : 0.977211594581604  loss1_3 : 1.0064687728881836  loss3_1 : 0.9829373955726624\n",
      " Epoch 30 -> loss totale : 0.11692839860916138  loss1 : 0.11692839860916138  loss3 : 1.0470834970474243  loss1_3 : 1.0798075199127197  loss3_1 : 0.9930416345596313\n",
      " Epoch 31 -> loss totale : 0.11889417469501495  loss1 : 0.11889417469501495  loss3 : 1.0447189807891846  loss1_3 : 1.083573341369629  loss3_1 : 1.031406283378601\n",
      " Epoch 32 -> loss totale : 0.10944917052984238  loss1 : 0.10944917052984238  loss3 : 1.0377659797668457  loss1_3 : 1.0721462965011597  loss3_1 : 1.0319547653198242\n",
      " Epoch 33 -> loss totale : 0.11286993324756622  loss1 : 0.11286993324756622  loss3 : 1.0380409955978394  loss1_3 : 1.0735291242599487  loss3_1 : 1.0648987293243408\n",
      " Epoch 34 -> loss totale : 0.10485397279262543  loss1 : 0.10485397279262543  loss3 : 1.1136332750320435  loss1_3 : 1.144140601158142  loss3_1 : 1.0247629880905151\n",
      " Epoch 35 -> loss totale : 0.10346336662769318  loss1 : 0.10346336662769318  loss3 : 1.0143725872039795  loss1_3 : 1.0587942600250244  loss3_1 : 1.054155945777893\n",
      " Epoch 36 -> loss totale : 0.10794450342655182  loss1 : 0.10794450342655182  loss3 : 0.9588578343391418  loss1_3 : 0.9919425845146179  loss3_1 : 0.9567646980285645\n",
      " Epoch 37 -> loss totale : 0.10141429305076599  loss1 : 0.10141429305076599  loss3 : 1.0590558052062988  loss1_3 : 1.0933879613876343  loss3_1 : 1.0247069597244263\n",
      " Epoch 38 -> loss totale : 0.10292965918779373  loss1 : 0.10292965918779373  loss3 : 0.9487630128860474  loss1_3 : 0.9831498265266418  loss3_1 : 0.9740515351295471\n",
      " Epoch 39 -> loss totale : 0.10464568436145782  loss1 : 0.10464568436145782  loss3 : 1.0295374393463135  loss1_3 : 1.066104769706726  loss3_1 : 1.0366100072860718\n",
      " Epoch 40 -> loss totale : 0.098261259496212  loss1 : 0.098261259496212  loss3 : 1.07085382938385  loss1_3 : 1.123410940170288  loss3_1 : 0.9662824869155884\n",
      " Epoch 41 -> loss totale : 0.10116074979305267  loss1 : 0.10116074979305267  loss3 : 1.0513789653778076  loss1_3 : 1.0915381908416748  loss3_1 : 0.9384783506393433\n",
      " Epoch 42 -> loss totale : 0.10000814497470856  loss1 : 0.10000814497470856  loss3 : 0.936867892742157  loss1_3 : 0.9724122881889343  loss3_1 : 1.0443449020385742\n",
      " Epoch 43 -> loss totale : 0.10015800595283508  loss1 : 0.10015800595283508  loss3 : 1.0212093591690063  loss1_3 : 1.0556013584136963  loss3_1 : 1.0341684818267822\n",
      " Epoch 44 -> loss totale : 0.09038560092449188  loss1 : 0.09038560092449188  loss3 : 1.0296193361282349  loss1_3 : 1.0742470026016235  loss3_1 : 1.0255967378616333\n",
      " Epoch 45 -> loss totale : 0.08858709037303925  loss1 : 0.08858709037303925  loss3 : 0.9188634753227234  loss1_3 : 0.9586952328681946  loss3_1 : 1.0291961431503296\n",
      " Epoch 46 -> loss totale : 0.0879235491156578  loss1 : 0.0879235491156578  loss3 : 0.9449529647827148  loss1_3 : 0.9808731079101562  loss3_1 : 1.0234649181365967\n",
      " Epoch 47 -> loss totale : 0.08833614736795425  loss1 : 0.08833614736795425  loss3 : 1.0193790197372437  loss1_3 : 1.0566526651382446  loss3_1 : 1.0005396604537964\n",
      " Epoch 48 -> loss totale : 0.08325609564781189  loss1 : 0.08325609564781189  loss3 : 1.021655797958374  loss1_3 : 1.066367745399475  loss3_1 : 1.0120617151260376\n",
      " Epoch 49 -> loss totale : 0.07576097548007965  loss1 : 0.07576097548007965  loss3 : 0.9671473503112793  loss1_3 : 1.0048305988311768  loss3_1 : 1.01055908203125\n",
      " Epoch 50 -> loss totale : 0.0803375244140625  loss1 : 0.0803375244140625  loss3 : 1.0530436038970947  loss1_3 : 1.0893168449401855  loss3_1 : 0.9491046667098999\n",
      " Epoch 51 -> loss totale : 0.08680415898561478  loss1 : 0.08680415898561478  loss3 : 0.9509435892105103  loss1_3 : 1.0021562576293945  loss3_1 : 0.9681128859519958\n",
      " Epoch 52 -> loss totale : 0.08125044405460358  loss1 : 0.08125044405460358  loss3 : 1.00753653049469  loss1_3 : 1.0681936740875244  loss3_1 : 1.1148079633712769\n",
      " Epoch 53 -> loss totale : 0.07530142366886139  loss1 : 0.07530142366886139  loss3 : 1.0271583795547485  loss1_3 : 1.0675381422042847  loss3_1 : 1.06789231300354\n",
      " Epoch 54 -> loss totale : 0.07362670451402664  loss1 : 0.07362670451402664  loss3 : 1.046565055847168  loss1_3 : 1.0885711908340454  loss3_1 : 0.9815279245376587\n",
      " Epoch 55 -> loss totale : 0.07477881759405136  loss1 : 0.07477881759405136  loss3 : 1.016486406326294  loss1_3 : 1.0626779794692993  loss3_1 : 1.0160263776779175\n",
      " Epoch 56 -> loss totale : 0.0767538845539093  loss1 : 0.0767538845539093  loss3 : 1.0469796657562256  loss1_3 : 1.0854051113128662  loss3_1 : 0.9620503187179565\n",
      " Epoch 57 -> loss totale : 0.07311132550239563  loss1 : 0.07311132550239563  loss3 : 1.0053257942199707  loss1_3 : 1.0581669807434082  loss3_1 : 0.9814618229866028\n",
      " Epoch 58 -> loss totale : 0.06767452508211136  loss1 : 0.06767452508211136  loss3 : 0.9921630024909973  loss1_3 : 1.0349410772323608  loss3_1 : 1.0242986679077148\n",
      " Epoch 59 -> loss totale : 0.06857718527317047  loss1 : 0.06857718527317047  loss3 : 0.9889118075370789  loss1_3 : 1.0240147113800049  loss3_1 : 0.9939102530479431\n",
      " Epoch 60 -> loss totale : 0.06783924251794815  loss1 : 0.06783924251794815  loss3 : 1.0030380487442017  loss1_3 : 1.051853895187378  loss3_1 : 1.0235905647277832\n",
      " Epoch 61 -> loss totale : 0.0656275749206543  loss1 : 0.0656275749206543  loss3 : 0.9870031476020813  loss1_3 : 1.0537135601043701  loss3_1 : 1.0208975076675415\n",
      " Epoch 62 -> loss totale : 0.06131932884454727  loss1 : 0.06131932884454727  loss3 : 1.0057045221328735  loss1_3 : 1.0549110174179077  loss3_1 : 1.040304183959961\n",
      " Epoch 63 -> loss totale : 0.06638946384191513  loss1 : 0.06638946384191513  loss3 : 0.9811668395996094  loss1_3 : 1.0299605131149292  loss3_1 : 1.038466215133667\n",
      " Epoch 64 -> loss totale : 0.06501816213130951  loss1 : 0.06501816213130951  loss3 : 1.0392799377441406  loss1_3 : 1.082135558128357  loss3_1 : 0.990469753742218\n",
      " Epoch 65 -> loss totale : 0.06062541529536247  loss1 : 0.06062541529536247  loss3 : 1.0227965116500854  loss1_3 : 1.0688709020614624  loss3_1 : 1.0637843608856201\n",
      " Epoch 66 -> loss totale : 0.06409234553575516  loss1 : 0.06409234553575516  loss3 : 0.9573699831962585  loss1_3 : 1.0008941888809204  loss3_1 : 1.0085303783416748\n",
      " Epoch 67 -> loss totale : 0.06244659423828125  loss1 : 0.06244659423828125  loss3 : 0.9610847234725952  loss1_3 : 1.018277645111084  loss3_1 : 1.065671682357788\n",
      " Epoch 68 -> loss totale : 0.061873167753219604  loss1 : 0.061873167753219604  loss3 : 1.0615040063858032  loss1_3 : 1.11146080493927  loss3_1 : 1.1364519596099854\n",
      " Epoch 69 -> loss totale : 0.0638197734951973  loss1 : 0.0638197734951973  loss3 : 1.002678394317627  loss1_3 : 1.065609335899353  loss3_1 : 0.9701675772666931\n",
      " Epoch 70 -> loss totale : 0.06200531870126724  loss1 : 0.06200531870126724  loss3 : 1.0181128978729248  loss1_3 : 1.0625003576278687  loss3_1 : 0.9520182013511658\n",
      " Epoch 71 -> loss totale : 0.060304030776023865  loss1 : 0.060304030776023865  loss3 : 1.0545933246612549  loss1_3 : 1.100043535232544  loss3_1 : 0.9907703995704651\n",
      " Epoch 72 -> loss totale : 0.055387165397405624  loss1 : 0.055387165397405624  loss3 : 1.0481055974960327  loss1_3 : 1.1097066402435303  loss3_1 : 1.0548286437988281\n",
      " Epoch 73 -> loss totale : 0.05898039788007736  loss1 : 0.05898039788007736  loss3 : 1.0574712753295898  loss1_3 : 1.0903877019882202  loss3_1 : 1.0021593570709229\n",
      " Epoch 74 -> loss totale : 0.05947896093130112  loss1 : 0.05947896093130112  loss3 : 1.078710675239563  loss1_3 : 1.1383002996444702  loss3_1 : 1.0251038074493408\n",
      " Epoch 75 -> loss totale : 0.05919920653104782  loss1 : 0.05919920653104782  loss3 : 1.0890512466430664  loss1_3 : 1.1583583354949951  loss3_1 : 1.0283539295196533\n",
      " Epoch 76 -> loss totale : 0.05565236136317253  loss1 : 0.05565236136317253  loss3 : 1.0447074174880981  loss1_3 : 1.0951144695281982  loss3_1 : 0.9898033738136292\n",
      " Epoch 77 -> loss totale : 0.05640638247132301  loss1 : 0.05640638247132301  loss3 : 1.0231494903564453  loss1_3 : 1.0717178583145142  loss3_1 : 1.0340975522994995\n",
      " Epoch 78 -> loss totale : 0.055917609483003616  loss1 : 0.055917609483003616  loss3 : 1.0064163208007812  loss1_3 : 1.0572936534881592  loss3_1 : 0.9876917600631714\n",
      " Epoch 79 -> loss totale : 0.05164843425154686  loss1 : 0.05164843425154686  loss3 : 1.0016148090362549  loss1_3 : 1.0665597915649414  loss3_1 : 1.0195260047912598\n",
      " Epoch 80 -> loss totale : 0.05503201484680176  loss1 : 0.05503201484680176  loss3 : 0.9841750860214233  loss1_3 : 1.0460903644561768  loss3_1 : 1.0822012424468994\n",
      " Epoch 81 -> loss totale : 0.054658953100442886  loss1 : 0.054658953100442886  loss3 : 0.992841362953186  loss1_3 : 1.0552867650985718  loss3_1 : 0.9839109182357788\n",
      " Epoch 82 -> loss totale : 0.05681820586323738  loss1 : 0.05681820586323738  loss3 : 1.0397491455078125  loss1_3 : 1.0974059104919434  loss3_1 : 1.1014220714569092\n",
      " Epoch 83 -> loss totale : 0.051876649260520935  loss1 : 0.051876649260520935  loss3 : 1.0263698101043701  loss1_3 : 1.0764623880386353  loss3_1 : 1.022735834121704\n",
      " Epoch 84 -> loss totale : 0.05897660180926323  loss1 : 0.05897660180926323  loss3 : 0.9696376919746399  loss1_3 : 1.0195586681365967  loss3_1 : 0.9781007170677185\n",
      " Epoch 85 -> loss totale : 0.05769281089305878  loss1 : 0.05769281089305878  loss3 : 1.0043269395828247  loss1_3 : 1.0581697225570679  loss3_1 : 1.1128535270690918\n",
      " Epoch 86 -> loss totale : 0.056054167449474335  loss1 : 0.056054167449474335  loss3 : 1.0086262226104736  loss1_3 : 1.0644805431365967  loss3_1 : 1.0076619386672974\n",
      " Epoch 87 -> loss totale : 0.05386732146143913  loss1 : 0.05386732146143913  loss3 : 1.0255229473114014  loss1_3 : 1.0780444145202637  loss3_1 : 0.9167501926422119\n",
      " Epoch 88 -> loss totale : 0.047930896282196045  loss1 : 0.047930896282196045  loss3 : 1.0440466403961182  loss1_3 : 1.0903781652450562  loss3_1 : 1.0005056858062744\n",
      " Epoch 89 -> loss totale : 0.054904062300920486  loss1 : 0.054904062300920486  loss3 : 0.9991573095321655  loss1_3 : 1.0568358898162842  loss3_1 : 0.9771465063095093\n",
      " Epoch 90 -> loss totale : 0.05165979638695717  loss1 : 0.05165979638695717  loss3 : 0.9320640563964844  loss1_3 : 0.9810640215873718  loss3_1 : 1.021356225013733\n",
      " Epoch 91 -> loss totale : 0.05079614743590355  loss1 : 0.05079614743590355  loss3 : 1.0527012348175049  loss1_3 : 1.114757776260376  loss3_1 : 1.0323431491851807\n",
      " Epoch 92 -> loss totale : 0.054151300340890884  loss1 : 0.054151300340890884  loss3 : 0.9538771510124207  loss1_3 : 1.0200769901275635  loss3_1 : 0.9910374879837036\n",
      " Epoch 93 -> loss totale : 0.05112835764884949  loss1 : 0.05112835764884949  loss3 : 1.0339109897613525  loss1_3 : 1.0782052278518677  loss3_1 : 0.9762684106826782\n",
      " Epoch 94 -> loss totale : 0.04933890327811241  loss1 : 0.04933890327811241  loss3 : 0.9824874997138977  loss1_3 : 1.031075358390808  loss3_1 : 1.0405091047286987\n",
      " Epoch 95 -> loss totale : 0.04882735386490822  loss1 : 0.04882735386490822  loss3 : 1.0513626337051392  loss1_3 : 1.1002919673919678  loss3_1 : 1.039269208908081\n",
      " Epoch 96 -> loss totale : 0.046347662806510925  loss1 : 0.046347662806510925  loss3 : 1.0233430862426758  loss1_3 : 1.0804522037506104  loss3_1 : 1.034958004951477\n",
      " Epoch 97 -> loss totale : 0.04811228811740875  loss1 : 0.04811228811740875  loss3 : 1.037906289100647  loss1_3 : 1.069005012512207  loss3_1 : 0.9864583611488342\n",
      " Epoch 98 -> loss totale : 0.04510222002863884  loss1 : 0.04510222002863884  loss3 : 1.0702908039093018  loss1_3 : 1.1201589107513428  loss3_1 : 1.0753968954086304\n",
      " Epoch 99 -> loss totale : 0.044766899198293686  loss1 : 0.044766899198293686  loss3 : 1.0272520780563354  loss1_3 : 1.0638703107833862  loss3_1 : 1.0188502073287964\n",
      " Epoch 100 -> loss totale : 0.04955543205142021  loss1 : 0.04955543205142021  loss3 : 1.055046558380127  loss1_3 : 1.1122902631759644  loss3_1 : 0.9900384545326233\n",
      " Epoch 101 -> loss totale : 0.04662812128663063  loss1 : 0.04662812128663063  loss3 : 1.0189733505249023  loss1_3 : 1.0775316953659058  loss3_1 : 1.0691543817520142\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    model1.train()\n",
    "    model3.train()\n",
    "    model1_3.train()\n",
    "    model3_1.train()\n",
    "    for (x1, _), (x2, _), (x3, y) in zip(*train_loaders):\n",
    "\n",
    "        if x1.size(0) != 32 or x3.size(0) != 32 or y.size(0) != 32:\n",
    "            continue\n",
    "\n",
    "       # Forward pass\n",
    "        o1, o3, o1_3, o3_1 = model1(x1), model3(x3), model1_3(x1), model3_1(x3)\n",
    "        loss = critere(o1, x1) + 0*critere(o3, x3) + 0*critere(o1_3, x3) + 0*critere(o3_1, x1)\n",
    "        # loss = critere(o1, x1) + critere(o3, x3) + critere(o1_3, x3) + critere(o3_1, x1)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer1.zero_grad()\n",
    "        optimizer3.zero_grad()\n",
    "        optimizer1_3.zero_grad()\n",
    "        optimizer3_1.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer1.step()\n",
    "        optimizer3.step()\n",
    "        optimizer1_3.step()\n",
    "        optimizer3_1.step()\n",
    "        \n",
    "\n",
    "    print(f' Epoch {epoch} -> loss totale :', loss.item(), \" loss1 :\", critere(o1, x1).item(), \" loss3 :\", critere(o3, x3).item(), \" loss1_3 :\", critere(o1_3, x3).item(), \" loss3_1 :\", critere(o3_1, x1).item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model1.eval()\n",
    "# model3.eval()\n",
    "model1_3.eval()\n",
    "model3_1.eval()\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    for (x1, _), (x2, _), (x3, y) in zip(*test_loaders):\n",
    "        o1, o3, o1_3, o3_1 = model1(x1), model3(x3), model1_3(x1), model3_1(x3)\n",
    "        loss = critere(o1, x1) + critere(o3, x3) + critere(o1_3, x3) + critere(o3_1, x1)\n",
    "        total_loss += loss.item()\n",
    "    print(f'Test Loss: {total_loss / len(test_loaders[0])}')\n",
    "    print(\" loss1 :\", critere(o1, x1).item(), \" loss3 :\", critere(o3, x3).item(), \" loss1_3 :\", critere(o1_3, x3).item(), \" loss3_1 :\", critere(o3_1, x1).item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
